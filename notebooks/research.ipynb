{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vanng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vanng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vanng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\vanng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')    # For tokenization\n",
    "nltk.download('averaged_perceptron_tagger')  # For POS tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't know who to blame, the timid writers o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film is one giant pant load. Paul Schrade...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The plot for Descent, if it actually can be ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Ghost of Dragstrip Hollow\" appears to take pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>At first i didn't think that Ben Affleck could...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>What would you expect from a film titled 'Surv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>This movie isn't as bad as I heard. It was enj...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>I laughed so hard during this movie my face hu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>`Europa' (or, as it is also known, `Zentropa')...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1125 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  category\n",
       "0     Airport '77 starts as a brand new luxury 747 p...         0\n",
       "1     I don't know who to blame, the timid writers o...         0\n",
       "2     This film is one giant pant load. Paul Schrade...         0\n",
       "3     The plot for Descent, if it actually can be ca...         0\n",
       "4     \"Ghost of Dragstrip Hollow\" appears to take pl...         0\n",
       "...                                                 ...       ...\n",
       "1120  At first i didn't think that Ben Affleck could...         1\n",
       "1121  What would you expect from a film titled 'Surv...         1\n",
       "1122  This movie isn't as bad as I heard. It was enj...         1\n",
       "1123  I laughed so hard during this movie my face hu...         1\n",
       "1124  `Europa' (or, as it is also known, `Zentropa')...         1\n",
       "\n",
       "[1125 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = \"../datasets/train\"\n",
    "categories = ['neg', 'pos']\n",
    "data = []\n",
    "\n",
    "def is_git_lfs_file(file_path):\n",
    "    \"\"\"\n",
    "    Check if a file is a Git LFS pointer\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        first_line = file.readline().strip()\n",
    "        return first_line.startswith(\"version https://git-lfs.github.com\")\n",
    "\n",
    "for category in categories:\n",
    "    category_path = os.path.join(train_path, category)\n",
    "    category= 0 if category == \"neg\" else 1\n",
    "\n",
    "    for filename in os.listdir(category_path):\n",
    "        file_path = os.path.join(category_path, filename)\n",
    "\n",
    "        if is_git_lfs_file(file_path): # skip Git LFS pointer files\n",
    "            continue\n",
    "\n",
    "        with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "            content = file.read().strip()\n",
    "        \n",
    "        data.append((content, category))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['content', 'category'])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Convert data from RAW to Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tokens(rawtext, verbose):\n",
    "    # 1. Tokenization\n",
    "    pattern = r'\\w+'\n",
    "    tokenizer = RegexpTokenizer(pattern)\n",
    "    token_words = tokenizer.tokenize(rawtext)\n",
    "    if (verbose):\n",
    "        print('Tokens:'+str(token_words[0:10]))\n",
    "    \n",
    "    # 2. Decapitalization\n",
    "    decap_token_words = [word.lower() for word in token_words]\n",
    "    if (verbose):\n",
    "        print(\"Decapitalized tokens:\" + str(decap_token_words[0:10]))\n",
    "    \n",
    "    # 3. Remove stop words\n",
    "    stopwords_nltk_en = set(stopwords.words('english'))\n",
    "    rmsw_token_words = ([word for word in token_words if word.lower() not in stopwords_nltk_en])\n",
    "    if (verbose):\n",
    "        print('Stopwords removed:' + str(rmsw_token_words[0:20]))\n",
    "    \n",
    "    # 4. Remove CAP words\n",
    "    rmcap_token_words = []\n",
    "    for word in rmsw_token_words:\n",
    "        if word.isupper():\n",
    "            rmcap_token_words.append(word.title())\n",
    "        else:\n",
    "            rmcap_token_words.append(word)\n",
    "    if (verbose):\n",
    "        print('CAPITALIZED removed:' + str(rmcap_token_words[0:20]))\n",
    "    \n",
    "    # 5. Remove salutation\n",
    "    salutation = ['mr', 'mrs', 'ms', 'dr', 'phd', 'prof', 'rev']\n",
    "    rmsalu_token_words = ([word for word in rmsw_token_words if word.lower() not in salutation])\n",
    "    if (verbose):\n",
    "        print('Salutation removed:' + str(rmsalu_token_words[0:20]))\n",
    "    \n",
    "    # 6. Define transfer tag function:\n",
    "    def transfer_tag(treebank_tag):\n",
    "        treebank_tag = treebank_tag.lower()\n",
    "        if treebank_tag.startswith('j'):\n",
    "            return \"a\"\n",
    "        elif treebank_tag.startswith('v'):\n",
    "            return \"v\"\n",
    "        elif treebank_tag.startswith('n'):\n",
    "            return 'n'\n",
    "        elif treebank_tag.startswith('r'):\n",
    "            return 'r'\n",
    "        else:\n",
    "            return 'n'\n",
    "    \n",
    "    # 7. Lemmatization\n",
    "    wnl = WordNetLemmatizer()\n",
    "\n",
    "    lemma_words = []\n",
    "    for word, tag in nltk.pos_tag(rmsalu_token_words):\n",
    "        firstletter = tag[0].lower()\n",
    "        wtag = transfer_tag(firstletter)\n",
    "        if not wtag:\n",
    "            lemma_words.extend([word])\n",
    "        else:\n",
    "            lemma_words.extend([wnl.lemmatize(word, wtag)])\n",
    "    if verbose:\n",
    "        print('Lemma:' + str(lemma_words[0:10]))\n",
    "    \n",
    "    # 8. English words\n",
    "    eng_words = [word for word in lemma_words if len(wn.synsets(word.lower())) > 1]\n",
    "\n",
    "    # 9 Remove numbers\n",
    "    rmnb_token_words = ([word for word in eng_words if not word.isdigit()])\n",
    "    if (verbose):\n",
    "        print('Number removed:' + str(rmnb_token_words[0:20]))\n",
    "    \n",
    "    return rmnb_token_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>0</td>\n",
       "      <td>[start, brand, new, luxury, plane, load, valua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't know who to blame, the timid writers o...</td>\n",
       "      <td>0</td>\n",
       "      <td>[know, blame, timid, writer, director, seem, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film is one giant pant load. Paul Schrade...</td>\n",
       "      <td>0</td>\n",
       "      <td>[film, one, giant, pant, load, Paul, lose, bad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The plot for Descent, if it actually can be ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>[plot, Descent, actually, call, plot, two, not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Ghost of Dragstrip Hollow\" appears to take pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Ghost, Hollow, appear, take, place, era, long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summer season is here when the choices in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Summer, season, choice, cinemas, limited, hot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shame on Yash Raj films and Aditya Chopra who ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Shame, film, seem, lose, intelligence, year, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>If this is a 2008 product from one of the bigg...</td>\n",
       "      <td>0</td>\n",
       "      <td>[product, one, big, production, house, Indian,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I had some expectation for the movie, since it...</td>\n",
       "      <td>0</td>\n",
       "      <td>[expectation, nice, star, cast, return, duo, W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I had a lot of expectations from this movie an...</td>\n",
       "      <td>0</td>\n",
       "      <td>[lot, expectation, Film, br, br, Jimmy, operat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  category  \\\n",
       "0  Airport '77 starts as a brand new luxury 747 p...         0   \n",
       "1  I don't know who to blame, the timid writers o...         0   \n",
       "2  This film is one giant pant load. Paul Schrade...         0   \n",
       "3  The plot for Descent, if it actually can be ca...         0   \n",
       "4  \"Ghost of Dragstrip Hollow\" appears to take pl...         0   \n",
       "5  Summer season is here when the choices in the ...         0   \n",
       "6  Shame on Yash Raj films and Aditya Chopra who ...         0   \n",
       "7  If this is a 2008 product from one of the bigg...         0   \n",
       "8  I had some expectation for the movie, since it...         0   \n",
       "9  I had a lot of expectations from this movie an...         0   \n",
       "\n",
       "                                              tokens  \n",
       "0  [start, brand, new, luxury, plane, load, valua...  \n",
       "1  [know, blame, timid, writer, director, seem, o...  \n",
       "2  [film, one, giant, pant, load, Paul, lose, bad...  \n",
       "3  [plot, Descent, actually, call, plot, two, not...  \n",
       "4  [Ghost, Hollow, appear, take, place, era, long...  \n",
       "5  [Summer, season, choice, cinemas, limited, hot...  \n",
       "6  [Shame, film, seem, lose, intelligence, year, ...  \n",
       "7  [product, one, big, production, house, Indian,...  \n",
       "8  [expectation, nice, star, cast, return, duo, W...  \n",
       "9  [lot, expectation, Film, br, br, Jimmy, operat...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenized = df.copy()\n",
    "[n, d] = df_tokenized.shape\n",
    "df_tokenized['tokens'] = ['']*n\n",
    "\n",
    "for index, row in df_tokenized.iterrows():\n",
    "    df_tokenized.at[index, \"tokens\"] = convert_tokens(row['content'], verbose = False)\n",
    "\n",
    "\n",
    "df_tokenized.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>3d</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abducts</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>...</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "      <th>zest</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zip</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.870769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 9076 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    3d aback abandon abandoned abandoning abbey abduct abducts abide ability  \\\n",
       "0  0.0   0.0     0.0       0.0        0.0   0.0    0.0     0.0   0.0     0.0   \n",
       "1  0.0   0.0     0.0       0.0        0.0   0.0    0.0     0.0   0.0     0.0   \n",
       "2  0.0   0.0     0.0       0.0        0.0   0.0    0.0     0.0   0.0     0.0   \n",
       "3  0.0   0.0     0.0       0.0        0.0   0.0    0.0     0.0   0.0     0.0   \n",
       "4  0.0   0.0     0.0       0.0        0.0   0.0    0.0     0.0   0.0     0.0   \n",
       "5  0.0   0.0     0.0       0.0        0.0   0.0    0.0     0.0   0.0     0.0   \n",
       "6  0.0   0.0     0.0       0.0        0.0   0.0    0.0     0.0   0.0     0.0   \n",
       "7  0.0   0.0     0.0       0.0        0.0   0.0    0.0     0.0   0.0     0.0   \n",
       "8  0.0   0.0     0.0       0.0        0.0   0.0    0.0     0.0   0.0     0.0   \n",
       "9  0.0   0.0     0.0       0.0        0.0   0.0    0.0     0.0   0.0     0.0   \n",
       "\n",
       "   ...  zen      zero zest zillion  zip zodiac zombie zombies zone zoom  \n",
       "0  ...  0.0  0.000000  0.0     0.0  0.0    0.0    0.0     0.0  0.0  0.0  \n",
       "1  ...  0.0  0.000000  0.0     0.0  0.0    0.0    0.0     0.0  0.0  0.0  \n",
       "2  ...  0.0  0.000000  0.0     0.0  0.0    0.0    0.0     0.0  0.0  0.0  \n",
       "3  ...  0.0  0.000000  0.0     0.0  0.0    0.0    0.0     0.0  0.0  0.0  \n",
       "4  ...  0.0  0.000000  0.0     0.0  0.0    0.0    0.0     0.0  0.0  0.0  \n",
       "5  ...  0.0  9.870769  0.0     0.0  0.0    0.0    0.0     0.0  0.0  0.0  \n",
       "6  ...  0.0  0.000000  0.0     0.0  0.0    0.0    0.0     0.0  0.0  0.0  \n",
       "7  ...  0.0  0.000000  0.0     0.0  0.0    0.0    0.0     0.0  0.0  0.0  \n",
       "8  ...  0.0  0.000000  0.0     0.0  0.0    0.0    0.0     0.0  0.0  0.0  \n",
       "9  ...  0.0  0.000000  0.0     0.0  0.0    0.0    0.0     0.0  0.0  0.0  \n",
       "\n",
       "[10 rows x 9076 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(norm=None)\n",
    "list_contents = []\n",
    "for index, row in df_tokenized.iterrows():\n",
    "    list_contents.append(\" \".join(row.tokens))\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(list_contents)\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=[tfidf_vectorizer.get_feature_names_out()])\n",
    "\n",
    "df_tfidf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X is the DataFrame containing TF-IDF features and y is the category column\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_tfidf, df_tokenized['category'], test_size=0.2, random_state=42, stratify=df_tokenized['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Apply models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Naive Bayes \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy for linear regression: 0.8422222222222222\n",
      "Cross-validation Accuracy for Naive Bayes: 0.8433333333333334\n",
      "Cross-validation Accuracy for Random Forest: 0.8044444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# Linear Regression:\n",
    "cv_scores_lr = cross_val_score(log_reg, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
    "print(\"Cross-validation Accuracy for linear regression:\", cv_scores_lr.mean())\n",
    "\n",
    "# Naive Bayes:\n",
    "cv_scores_nb = cross_val_score(nb, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
    "print(\"Cross-validation Accuracy for Naive Bayes:\", cv_scores_nb.mean())\n",
    "\n",
    "# Random Forest:\n",
    "cv_scores_rf = cross_val_score(rf, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
    "print(\"Cross-validation Accuracy for Random Forest:\", cv_scores_rf.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow\">Cross validation for naive_bayes score was the highest: 0.843</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 30/31 [01:00<00:01,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 464, number of negative: 436\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3795\n",
      "[LightGBM] [Info] Number of data points in the train set: 900, number of used features: 780\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.515556 -> initscore=0.062242\n",
      "[LightGBM] [Info] Start training from score 0.062242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:01<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "BernoulliNB                        0.85               0.85     0.85      0.85   \n",
      "NearestCentroid                    0.84               0.84     0.84      0.84   \n",
      "RandomForestClassifier             0.83               0.83     0.83      0.83   \n",
      "ExtraTreesClassifier               0.83               0.82     0.82      0.83   \n",
      "LogisticRegression                 0.81               0.81     0.81      0.81   \n",
      "RidgeClassifierCV                  0.80               0.80     0.80      0.80   \n",
      "RidgeClassifier                    0.80               0.80     0.80      0.80   \n",
      "XGBClassifier                      0.80               0.79     0.79      0.80   \n",
      "LinearSVC                          0.80               0.79     0.79      0.79   \n",
      "PassiveAggressiveClassifier        0.80               0.79     0.79      0.79   \n",
      "NuSVC                              0.79               0.79     0.79      0.79   \n",
      "LGBMClassifier                     0.79               0.79     0.79      0.79   \n",
      "CalibratedClassifierCV             0.79               0.79     0.79      0.79   \n",
      "SGDClassifier                      0.78               0.78     0.78      0.78   \n",
      "Perceptron                         0.77               0.77     0.77      0.77   \n",
      "BaggingClassifier                  0.74               0.74     0.74      0.74   \n",
      "AdaBoostClassifier                 0.72               0.72     0.72      0.72   \n",
      "DecisionTreeClassifier             0.70               0.70     0.70      0.70   \n",
      "GaussianNB                         0.64               0.64     0.64      0.64   \n",
      "SVC                                0.64               0.64     0.64      0.63   \n",
      "ExtraTreeClassifier                0.64               0.63     0.63      0.64   \n",
      "LinearDiscriminantAnalysis         0.60               0.60     0.60      0.59   \n",
      "KNeighborsClassifier               0.53               0.51     0.51      0.38   \n",
      "LabelSpreading                     0.48               0.50     0.50      0.32   \n",
      "LabelPropagation                   0.48               0.50     0.50      0.32   \n",
      "DummyClassifier                    0.52               0.50     0.50      0.35   \n",
      "QuadraticDiscriminantAnalysis      0.49               0.48     0.48      0.40   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "BernoulliNB                          0.60  \n",
      "NearestCentroid                      0.72  \n",
      "RandomForestClassifier               2.07  \n",
      "ExtraTreesClassifier                 4.19  \n",
      "LogisticRegression                   0.74  \n",
      "RidgeClassifierCV                    0.90  \n",
      "RidgeClassifier                      0.72  \n",
      "XGBClassifier                        2.78  \n",
      "LinearSVC                            1.18  \n",
      "PassiveAggressiveClassifier          0.83  \n",
      "NuSVC                                6.71  \n",
      "LGBMClassifier                       1.15  \n",
      "CalibratedClassifierCV               2.45  \n",
      "SGDClassifier                        0.71  \n",
      "Perceptron                           0.70  \n",
      "BaggingClassifier                    5.25  \n",
      "AdaBoostClassifier                   7.87  \n",
      "DecisionTreeClassifier               1.86  \n",
      "GaussianNB                           0.68  \n",
      "SVC                                  6.66  \n",
      "ExtraTreeClassifier                  0.60  \n",
      "LinearDiscriminantAnalysis           4.32  \n",
      "KNeighborsClassifier                 1.00  \n",
      "LabelSpreading                       0.78  \n",
      "LabelPropagation                     1.31  \n",
      "DummyClassifier                      0.55  \n",
      "QuadraticDiscriminantAnalysis        2.38  ,                                Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "BernoulliNB                        0.85               0.85     0.85      0.85   \n",
      "NearestCentroid                    0.84               0.84     0.84      0.84   \n",
      "RandomForestClassifier             0.83               0.83     0.83      0.83   \n",
      "ExtraTreesClassifier               0.83               0.82     0.82      0.83   \n",
      "LogisticRegression                 0.81               0.81     0.81      0.81   \n",
      "RidgeClassifierCV                  0.80               0.80     0.80      0.80   \n",
      "RidgeClassifier                    0.80               0.80     0.80      0.80   \n",
      "XGBClassifier                      0.80               0.79     0.79      0.80   \n",
      "LinearSVC                          0.80               0.79     0.79      0.79   \n",
      "PassiveAggressiveClassifier        0.80               0.79     0.79      0.79   \n",
      "NuSVC                              0.79               0.79     0.79      0.79   \n",
      "LGBMClassifier                     0.79               0.79     0.79      0.79   \n",
      "CalibratedClassifierCV             0.79               0.79     0.79      0.79   \n",
      "SGDClassifier                      0.78               0.78     0.78      0.78   \n",
      "Perceptron                         0.77               0.77     0.77      0.77   \n",
      "BaggingClassifier                  0.74               0.74     0.74      0.74   \n",
      "AdaBoostClassifier                 0.72               0.72     0.72      0.72   \n",
      "DecisionTreeClassifier             0.70               0.70     0.70      0.70   \n",
      "GaussianNB                         0.64               0.64     0.64      0.64   \n",
      "SVC                                0.64               0.64     0.64      0.63   \n",
      "ExtraTreeClassifier                0.64               0.63     0.63      0.64   \n",
      "LinearDiscriminantAnalysis         0.60               0.60     0.60      0.59   \n",
      "KNeighborsClassifier               0.53               0.51     0.51      0.38   \n",
      "LabelSpreading                     0.48               0.50     0.50      0.32   \n",
      "LabelPropagation                   0.48               0.50     0.50      0.32   \n",
      "DummyClassifier                    0.52               0.50     0.50      0.35   \n",
      "QuadraticDiscriminantAnalysis      0.49               0.48     0.48      0.40   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "BernoulliNB                          0.60  \n",
      "NearestCentroid                      0.72  \n",
      "RandomForestClassifier               2.07  \n",
      "ExtraTreesClassifier                 4.19  \n",
      "LogisticRegression                   0.74  \n",
      "RidgeClassifierCV                    0.90  \n",
      "RidgeClassifier                      0.72  \n",
      "XGBClassifier                        2.78  \n",
      "LinearSVC                            1.18  \n",
      "PassiveAggressiveClassifier          0.83  \n",
      "NuSVC                                6.71  \n",
      "LGBMClassifier                       1.15  \n",
      "CalibratedClassifierCV               2.45  \n",
      "SGDClassifier                        0.71  \n",
      "Perceptron                           0.70  \n",
      "BaggingClassifier                    5.25  \n",
      "AdaBoostClassifier                   7.87  \n",
      "DecisionTreeClassifier               1.86  \n",
      "GaussianNB                           0.68  \n",
      "SVC                                  6.66  \n",
      "ExtraTreeClassifier                  0.60  \n",
      "LinearDiscriminantAnalysis           4.32  \n",
      "KNeighborsClassifier                 1.00  \n",
      "LabelSpreading                       0.78  \n",
      "LabelPropagation                     1.31  \n",
      "DummyClassifier                      0.55  \n",
      "QuadraticDiscriminantAnalysis        2.38  )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "lazy_clf = LazyClassifier()\n",
    "clf_models = lazy_clf.fit(X_train, X_test, y_train, y_test)\n",
    "print(clf_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow\">From the result table, Naive Bayes (BernoulliNB) gave the best score: 0.85 for accuracy, balanced accuracy and F1 score</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.01, 'solver': 'lbfgs'}\n",
      "Best Validation Accuracy: 0.8477777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'solver': ['liblinear', 'lbfgs']  # Different solvers for optimization\n",
    "}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation (cv=5 means 5-fold)\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=500), param_grid_lr, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Validation Accuracy:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. For Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: {'alpha': 10}\n",
      "Best Validation Accuracy: 0.8677777777777778\n"
     ]
    }
   ],
   "source": [
    "param_grid_nb = {'alpha': [0.01, 0.1, 1, 10]}  # Smoothing parameter\n",
    "grid_search_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=5, scoring='accuracy')\n",
    "grid_search_nb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Alpha:\", grid_search_nb.best_params_)\n",
    "print(\"Best Validation Accuracy:\", grid_search_nb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. For Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best Validation Accuracy: 0.8177777777777778\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=3, scoring='accuracy')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search_rf.best_params_)\n",
    "print(\"Best Validation Accuracy:\", grid_search_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8533333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84       109\n",
      "           1       0.83      0.90      0.86       116\n",
      "\n",
      "    accuracy                           0.85       225\n",
      "   macro avg       0.86      0.85      0.85       225\n",
      "weighted avg       0.86      0.85      0.85       225\n",
      "\n",
      "Naïve Bayes Accuracy: 0.8488888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       109\n",
      "           1       0.85      0.85      0.85       116\n",
      "\n",
      "    accuracy                           0.85       225\n",
      "   macro avg       0.85      0.85      0.85       225\n",
      "weighted avg       0.85      0.85      0.85       225\n",
      "\n",
      "Confusion Matrix for Naive Bayes: \n",
      "[[92 17]\n",
      " [17 99]]\n",
      "Random Forest Accuracy: 0.8266666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81       109\n",
      "           1       0.80      0.89      0.84       116\n",
      "\n",
      "    accuracy                           0.83       225\n",
      "   macro avg       0.83      0.82      0.83       225\n",
      "weighted avg       0.83      0.83      0.83       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Use best models from hyperparameter tuning:\n",
    "best_lr = grid_search.best_estimator_\n",
    "best_nb = grid_search_nb.best_estimator_\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# Logistic Regression Evaluation\n",
    "y_pred_log_reg = best_lr.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "\n",
    "# Naive Bayes Evaluation\n",
    "y_pred_nb = best_nb.predict(X_test)\n",
    "print(\"Naïve Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "print(f\"Confusion Matrix for Naive Bayes: \\n{confusion_matrix(y_test, y_pred_nb)}\")\n",
    "\n",
    "# Random Forest Evaluation\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
